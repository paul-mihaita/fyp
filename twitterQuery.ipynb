{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access token: 1088736062548164608-WNXuMGPWX6eeCTmQH4ZPimYuAMFIV6\n",
    "# access token secret: kPuHJbpxL8LNpmt5azMxhX8zJ5xdSfTjz1f09J4EBXWUo\n",
    "# API key: D47QJqNbG66KSJUw6pOEnieWw\n",
    "# API secret key: lSq17uyRnnNVUVIwXmHgf43P1LQB7dX6horFt9Vqtz25bqCKIe\n",
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import string\n",
    "import nltk\n",
    "import math\n",
    "from joblib import dump, load\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from helper_functions import *\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient(object): \n",
    "    ''' \n",
    "    Generic Twitter Class for sentiment analysis. \n",
    "    '''\n",
    "    def __init__(self): \n",
    "        ''' \n",
    "        Class constructor or initialization method. \n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        consumer_key = 'D47QJqNbG66KSJUw6pOEnieWw'\n",
    "        consumer_secret = 'lSq17uyRnnNVUVIwXmHgf43P1LQB7dX6horFt9Vqtz25bqCKIe'\n",
    "        access_token = '1088736062548164608-WNXuMGPWX6eeCTmQH4ZPimYuAMFIV6'\n",
    "        access_token_secret = 'kPuHJbpxL8LNpmt5azMxhX8zJ5xdSfTjz1f09J4EBXWUo'\n",
    "  \n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "  \n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "  \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'\n",
    "  \n",
    "    def get_tweets(self, query, count = 10): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them. \n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "        fetched_tweets = {}\n",
    "        fetched_tweets['tweet'] = []\n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched= self.api.search(q = query, count = count)\n",
    "            for tweet in fetched:\n",
    "                fetched_tweets['tweet'].append(tweet.text)\n",
    "\n",
    "            df = pd.DataFrame(fetched_tweets, columns = ['tweet'])\n",
    "\n",
    "            #fetched_tweets['tweet'] = fetched_tweets['tweet'].tolist()\n",
    "            fetched_tweets = clean_tweets(df)\n",
    "            text_classifier = loadModel()\n",
    "            #tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "            #loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=pickle.load(open(\"feature.pkl\", \"rb\")))\n",
    "            #tfidf = transformer.fit_transform(loaded_vec.fit_transform(np.array([\"aaa ccc eee\"])))\n",
    "            tfidf_vectorizer = load(\"tfidf.pkl\")\n",
    "\n",
    "            test_tfidf = tfidf_vectorizer.transform(fetched_tweets['tidy_tweet'])\n",
    "            predictions = text_classifier.predict(test_tfidf)\n",
    "            i = 0\n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "  \n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = tweet.text + '\\n'\n",
    "                # saving sentiment of tweet \n",
    "                #parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "                parsed_tweet['sentiment'] = predictions[i]\n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                        i = i + 1\n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "                    i = i + 1\n",
    "            # return parsed tweets \n",
    "            return tweets \n",
    "  \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter keyword for search:\n",
      "Jew\n",
      "Which technique to use for training?\n",
      "1. Logistic Regression\n",
      "2. Random Forest\n",
      "3. SVC , polynomial\n",
      "4. SVC, gaussian\n",
      "5. SVC, sigmoid\n",
      "6. K-nearest \n",
      "Please enter a number from 1 to 6\n",
      "2\n",
      "racist/sexist tweets percentage: 2.5 %\n",
      "non racist/sexist tweets percentage: 97.5 %\n",
      "\n",
      "\n",
      "racist/sexist tweets:\n",
      "@BeccaTheWitz He blocked me because I liked a reply someone wrote to him.\n",
      "\n",
      "I think he was one of the \"as a Jew\" cri… https://t.co/pjhC8tBsw2\n",
      "\n",
      "@Marston4ca42 I'm a Jew. Proverbs was written in Hebrew, a language I can read I told him the \"rod\" meant to have b… https://t.co/iVC465U0FB\n",
      "\n",
      "\n",
      "\n",
      "non racist/sexist tweets:\n",
      "The only reason anyone supports Biden is they want to stop the Jew from giving everyone housing, healthcare, &amp; an e… https://t.co/6qQP2sTVsX\n",
      "\n",
      "RT @Render64: Hey Ireland, come get your Jew hater, before he loses his account. https://t.co/886Rw1bNqW\n",
      "\n",
      "RT @kampeas: Sanders definitely has chits as a proud pro-Israel Jew. Taking on yellers in Vt in 2014, making public Hanukkah a thing in Bur…\n",
      "\n",
      "RT @DavidHarrisAJC: ZAKYNTHOS is a Greek island. During WW2, something incredible happened there. Germans occupied it, called the mayor &amp; b…\n",
      "\n",
      "@fiona_gill @jew_charlotte30 @FestHeretic @WeAreInglorious @TheNathanJames Oooh u off darn sarf? To Larnden? \n",
      "Not s… https://t.co/C9wKB4i26q\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    word = input(\"Enter keyword for search:\" + '\\n')\n",
    "    tweets = api.get_tweets(query = word , count = 300)\n",
    "\n",
    "    # picking racist/sexist tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 1] \n",
    "    # percentage of racist/sexist tweets \n",
    "    print(\"racist/sexist tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    # picking non racist/sexist tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 0] \n",
    "    # percentage of non racist/sexist tweets \n",
    "    print(\"non racist/sexist tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "  \n",
    "    # printing first 5 racist/sexist tweets \n",
    "    print(\"\\n\\nracist/sexist tweets:\") \n",
    "    for tweet in ptweets[:5]: \n",
    "        print(tweet['text']) \n",
    "  \n",
    "    # printing first 5 non racist/sexist tweets \n",
    "    print(\"\\n\\nnon racist/sexist tweets:\") \n",
    "    for tweet in ntweets[:5]: \n",
    "        print(tweet['text']) \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
